# Тестовое задание на позицию Junior Python Programmer (стажер) для Lesta Studio

## Задание 1


<details>
  <summary>Условие задания</summary>

На языке Python реализовать алгоритм (функцию) определения четности целого числа, который будет аналогичен нижеприведенному по функциональности, но отличен по своей сути. Объяснить плюсы и минусы обеих реализаций.

Python example:
```python
def isEven(value):
   return value % 2 == 0
```

</details>


​Исходный код: [ссылка](isEven.py)



**Сравниваем варианты:**

```python
def isEven(value):
    return value % 2 == 0
```

В приведенном примере функция возвращает True если число делится на 2 без остатка, самый простой для понимания способ.

```python
def isEvenBit(value):
    return not value & 1
```

Написаная функция аналогична по функциональности, но использует побитовый оператор &. Для целых чисел, если младший бит равен 1, то число нечетное (основываясь на преобразовании двоичных чисел в десятичные). Результат переведем в логический тип оператором not. Поскольку побитовые операторы проводят операции непосредственно на битах числа, данный варинат должен выполняться быстрее. Проверим это многократным вызовом функций.

Тестирование показало что побитовый оператор работает медленнее на массиве из 10 000 случайных чисел от 0 до 100 000. Возможно это вызвано работой интерпретатора, или тем что в Python int - объект не фиксированного размера.
```
Example: 0.00099945068359375s
Bit &  : 0.002012014389038086s
-------------------------------
Example: 0.0019989013671875s
Bit &  : 0.002001047134399414s
-------------------------------
Example: 0.00099945068359375s
Bit &  : 0.002012014389038086s
```
Ища ответ на вопрос почему в Python это происходит так нашел мнение, что оператор % быстрый путь вычисления для `single-"limb" integers`, а побитовый & - нет. Получается нужно попробывать провести тест с числами больше чем 2^30.

Проверка на массиве из случйных чисел от 9млрд до 99млрд побитовый оператор & работает в среднем не медленнее, чем %, в лучших случаях двукратно быстрее.
```
Example: 0.0019986629486083984s
Bit &  : 0.0019834041595458984s
--------------------------------
Example: 0.0029990673065185547s
Bit &  : 0.0019969940185546875s
--------------------------------
Example: 0.0019986629486083984s
Bit &  : 0.00099945068359375s
```

#### Подводя итоги
На языке Python при работе с числами до миллиардов выгодне использовать приведенный в примере вариант, при большех же числах, не помещающихся в 32ухбитную ячейку памяти - побитовый.

## Задание 2

<details>
  <summary>Условие задания</summary>

На языке Python (2.7) реализовать минимум по 2 класса реализовывающих циклический буфер FIFO. Объяснить плюсы и минусы каждой реализации.

</details>

**​Исходный код:**
1. Вариант через список [ссылка](ringBuffer.py)
2. При добавлении в заполненый буфер, вместо перезаписи - исключение [ссылка](ringBuffer_rwe.py)
3. Вариант через collections.deque() [ссылка](ringBuffer_d.py)

Первый вариант - классический кольцевой буфер, основанный на списке. При инициализации мы создаем список нужного размера, заполненный нулями, счетчик элементов и два указателя (куда записывать и откуда считывать, оба переходят в начало списка, когда доходят до конца). При записи в заполненный буфер перезаписывает элемент, который был первым добавлен. При получении элемента из буфера мы просто смещаем указатель чтения.

Второй вариант - аналогичен предыдущему, но при попытке записи в заполеннный буфер выбрасывается исключение, что предотвратит потерю данных.

Третий вариант - так же запрещает перезапись данных, но реализован на collections.deque(). В отличие от первых двух считаные элементы не будут оставаться в памяти, а запись/извлечение элемента буфера будет по прежднему осущетвляться за O(1).

## Задание 3

<details>
  <summary>Условие задания</summary>

На языке Python реализовать функцию, которая быстрее всего (по процессорным тикам) отсортирует данный ей массив чисел. Массив может быть любого размера со случайным порядком чисел (в том числе и отсортированным). Объяснить почему вы считаете, что функция соответствует заданным критериям.

</details>


​Исходный код: [ссылка](sort.py)

Без примера данных невозможно выбрать лучшую функцию сортировки. Для небольших массивов разница между O(n) , O(n*logn) и O(n^2) будет практически незаметна, а сортировка расческой будет быстрее быстрой. Для уже отсортированых массивов неэффективные O(n^2) сортировки, такие как пузырьком, перемешиванием, вставками, окажутся более эффективными и, в случае с первыми двумя не затратными по памяти.

* Говоря о популярных эффективных сортировках если нам необходима стабильная и устойчивая то подойдет Сортировка слиянием и ее гибриды (такие как встроенный в Python.sorted() Timsort). 
Не устойчивые сортировки:
* Всем известная Быстрая сортировка (Тони Хоара) во многих случаях будет быстрее сортировки слиянием, но в случаях выбора в качесте опорной точки худших (максимальных и минимальных) элементов массива будет уходить в O(n^2).
* Сортировка Кучей будет более стабильной и хорошо справляться в случае наличия одинаковых ключей

Для проверки вышесказанного возьмем три типа длинных массивов:
1. Созданый из случайных чисел
2. Отсортированный
3. Состоящий из отсортированных частей

И проверим их несколькими функциями сортировки:

1. Быстрой сортировкой
2. Сортировкой слиянием
3. Сортировкой вставками для уже отсортировнного массива
4. Встроенным в Python Timsort, который основывается на идее того что сортируемые массивы данных часто содержат в себе упорядоченные подмассивы и является гибридом сортировки вставками и слиянием
> Timsort скорее всего покажет себя быстре всеего еще и из-за того что написан на C

```
Случайный массив
quick_sort: 0.2478642463684082s
merge_sort: 0.4917268753051758s
sorted: 0.02098250389099121s
Отсортированный массив
quick_sort: 0.43175578117370605s
merge_sort: 0.2928452491760254s
sorted: 0.0020041465759277344s
insert_sort: 0.01098489761352539s
Массив из отсортированных частей
quick_sort: 0.039971351623535156s
merge_sort: 0.44375181198120117s
sorted: 0.005975246429443359s
```

Довольно показательный тест, из которого можно сделать следующие выводы:
* На отсортированных массивах сортировка вставками действительно гораздо быстрее эффективных сортировок
* Быстрая сортировка выбирала "плохие" опорные элементы в отсортированном массиве и проиграла сортировке вставками. При этом на массиве из отсортированных одинаковых частей, где это сделать невозможно показала результаты сопостовимые с прошлым пунктом.
* Timsort, написаный на C, показывает лучшие результаты, в особенности на отсортированных/частично отсортированных массивах

#### Подводя итоги
Нет идеальной сортировки для абстрактных данных, но говоря о сортировках в Python выгоднее использовать встроенный Timsort. Или же выбрать оптимальную сортировку, изходя из представления об имеющихся данных и реализовать ее на компилируемом языке строгой типизации (С, в случае с sorted, или Go например). 
> В пользу Timsort или же двоичного дерева так же можно привести [таблицу](https://hsto.org/r/w1560/storage1/61a272a8/54806d34/69954080/310f329f.png) с Википедии, где они единственные стабильные и со сложностью O(n) в лучшем случае, имея O(n logn) в худшем и средем.